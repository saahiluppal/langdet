{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = {\n",
    "    0: 'Danish', 1: 'German',\n",
    "    2: 'Greek', 3: 'English',\n",
    "    4: 'Spanish', 5: 'Finnish',\n",
    "    6: 'French', 7: 'Italian',\n",
    "    8: 'Dutch', 9: 'Portuguese',\n",
    "    10: 'Swedish', 11: 'Bulgarian',\n",
    "    12: 'Czech', 13: 'Estonian',\n",
    "    14: 'Hungarian', 15: 'Lithuanian',\n",
    "    16: 'Latvian', 17: 'Polish',\n",
    "    18: 'Romanian', 19: 'Slovak',\n",
    "    20: 'Slovenian'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_language(language):\n",
    "    with open(os.getcwd() + '/dataset/' + language +\".txt\") as outfile:\n",
    "        lang = outfile.read()\n",
    "    return lang\n",
    "\n",
    "def clean(language):\n",
    "    pattern = r'<(!?).*>'    \n",
    "    \n",
    "    language = re.sub(pattern, '', language)\n",
    "    \n",
    "    language = ''.join([i for i in language if not i.isdigit()])\n",
    "    language = ''.join([i for i in language if i not in \"(){}[]\\n,'\"])\n",
    "    \n",
    "    language = sent_tokenize(language)\n",
    "    language = [i for i in language if len(i)> 4]\n",
    "    return language\n",
    "    \n",
    "def stack(sentences, langauge_id, language):\n",
    "    length = len(sentences)\n",
    "    \n",
    "    target = [langauge_id] * length\n",
    "    lang = [language] * length\n",
    "    \n",
    "    df = pd.DataFrame(np.c_[sentences, target, lang], columns=['Sentences','Target', 'Language'])\n",
    "    return df\n",
    "\n",
    "def shuffle(dataframe):\n",
    "    return dataframe.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "def preprocess():\n",
    "    data = pd.DataFrame([])\n",
    "    for code,language in languages.items():\n",
    "        extracted = extract_language(language.lower())\n",
    "        cleaned = clean(extracted)\n",
    "        dataframe = stack(cleaned, code, language)\n",
    "        \n",
    "        data = data.append(dataframe, ignore_index=True)\n",
    "    data = shuffle(data)\n",
    "    data['Target'] = data['Target'].astype(int)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_lines():\n",
    "    sum = 0\n",
    "    for code, lang in languages.items():\n",
    "        extracted = extract_language(lang.lower())\n",
    "        cleaned = clean(extracted)\n",
    "        sum += len(cleaned)\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "993071"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_lines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Target</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>È assolutamente scandaloso quale che sia il me...</td>\n",
       "      <td>7</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Има обаче един факт който не може да бъде прен...</td>\n",
       "      <td>11</td>\n",
       "      <td>Bulgarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Het gaat om een echte monopolierichtlijn want ...</td>\n",
       "      <td>8</td>\n",
       "      <td>Dutch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Puola on yksi suurista toivoa herättävistä mer...</td>\n",
       "      <td>5</td>\n",
       "      <td>Finnish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prav tako to ni vprašanje napredka in šele poz...</td>\n",
       "      <td>20</td>\n",
       "      <td>Slovenian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993066</th>\n",
       "      <td>Meidän täällä parlamentissa on torjuttava uusi...</td>\n",
       "      <td>5</td>\n",
       "      <td>Finnish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993067</th>\n",
       "      <td>To môže byť prípad budov ktoré samozrejme pred...</td>\n",
       "      <td>19</td>\n",
       "      <td>Slovak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993068</th>\n",
       "      <td>Indholdet er nemlig ikke længere kun afhængig ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Danish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993069</th>\n",
       "      <td>În calitate de deputați în Parlamentul Europea...</td>\n",
       "      <td>18</td>\n",
       "      <td>Romanian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993070</th>\n",
       "      <td>No entanto a data da sentença um mês antes do ...</td>\n",
       "      <td>9</td>\n",
       "      <td>Portuguese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>993071 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Sentences  Target    Language\n",
       "0       È assolutamente scandaloso quale che sia il me...       7     Italian\n",
       "1       Има обаче един факт който не може да бъде прен...      11   Bulgarian\n",
       "2       Het gaat om een echte monopolierichtlijn want ...       8       Dutch\n",
       "3       Puola on yksi suurista toivoa herättävistä mer...       5     Finnish\n",
       "4       Prav tako to ni vprašanje napredka in šele poz...      20   Slovenian\n",
       "...                                                   ...     ...         ...\n",
       "993066  Meidän täällä parlamentissa on torjuttava uusi...       5     Finnish\n",
       "993067  To môže byť prípad budov ktoré samozrejme pred...      19      Slovak\n",
       "993068  Indholdet er nemlig ikke længere kun afhængig ...       0      Danish\n",
       "993069  În calitate de deputați în Parlamentul Europea...      18    Romanian\n",
       "993070  No entanto a data da sentença um mês antes do ...       9  Portuguese\n",
       "\n",
       "[993071 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Target'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          7\n",
       "1         11\n",
       "2          8\n",
       "3          5\n",
       "4         20\n",
       "          ..\n",
       "993066     5\n",
       "993067    19\n",
       "993068     0\n",
       "993069    18\n",
       "993070     9\n",
       "Name: Target, Length: 993071, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y = tf.keras.utils.to_categorical(data['Target'], num_classes=21)\n",
    "y = data['Target']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = tf.keras.preprocessing.text.Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok.fit_on_texts(data['Sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = tok.texts_to_sequences(data['Sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1050037"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = len(tok.word_index) + 1\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = tf.keras.preprocessing.sequence.pad_sequences(texts,maxlen=(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=vocab,\n",
    "                              output_dim=128,\n",
    "                             input_length=100),\n",
    "    #tf.keras.layers.LSTM(200),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(21, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 128)          134404736 \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 21)                268821    \n",
      "=================================================================\n",
      "Total params: 134,673,557\n",
      "Trainable params: 134,673,557\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pad, np.array(y), test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 893763 samples, validate on 99308 samples\n",
      "Epoch 1/100\n",
      "893763/893763 [==============================] - 2027s 2ms/sample - loss: 0.1291 - accuracy: 0.9786 - val_loss: 0.0158 - val_accuracy: 0.9963\n",
      "Epoch 2/100\n",
      "893763/893763 [==============================] - 2670s 3ms/sample - loss: 0.0122 - accuracy: 0.9973 - val_loss: 0.0120 - val_accuracy: 0.9970\n",
      "Epoch 3/100\n",
      "893763/893763 [==============================] - 3132s 4ms/sample - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.0117 - val_accuracy: 0.9969\n",
      "Epoch 4/100\n",
      "893763/893763 [==============================] - 2515s 3ms/sample - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.0113 - val_accuracy: 0.9971\n",
      "Epoch 5/100\n",
      "893763/893763 [==============================] - 3102s 3ms/sample - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.0115 - val_accuracy: 0.9972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f75e9acec50>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=100, batch_size=512, validation_data=(X_test, y_test),\n",
    "          callbacks=[tf.keras.callbacks.EarlyStopping(),\n",
    "                     tf.keras.callbacks.TensorBoard(log_dir='./graph', write_graph=True, write_images=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_two.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer_two.json', 'wb') as handle:\n",
    "    pickle.dump(tok, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer_two.json', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Just testing :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = ['hello world']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tf.keras.preprocessing.sequence.pad_sequences(tok.texts_to_sequences(test_text), maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages.get(model.predict_classes(text)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[515459, 2546]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(test_text), maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages.get(model.predict_classes(text)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
