{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = {\n",
    "    0: 'Danish', 1: 'German',\n",
    "    2: 'Greek', 3: 'English',\n",
    "    4: 'Spanish', 5: 'Finnish',\n",
    "    6: 'French', 7: 'Italian',\n",
    "    8: 'Dutch', 9: 'Portuguese',\n",
    "    10: 'Swedish', 11: 'Bulgarian',\n",
    "    12: 'Czech', 13: 'Estonian',\n",
    "    14: 'Hungarian', 15: 'Lithuanian',\n",
    "    16: 'Latvian', 17: 'Polish',\n",
    "    18: 'Romanian', 19: 'Slovak',\n",
    "    20: 'Slovenian'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_language(language):\n",
    "    with open(os.getcwd() + '/dataset/' + language +\".txt\") as outfile:\n",
    "        lang = outfile.read()\n",
    "    return lang.lower()\n",
    "\n",
    "def clean(language):\n",
    "    pattern = r'<(!?).*>'    \n",
    "    \n",
    "    language = re.sub(pattern, '', language)\n",
    "    \n",
    "    language = ''.join([i for i in language if not i.isdigit()])\n",
    "    language = ''.join([i for i in language if i not in \"(){}[]\\n,'\"])\n",
    "    \n",
    "    language = sent_tokenize(language)\n",
    "    language = [i for i in language if len(i)> 4]\n",
    "    return language\n",
    "    \n",
    "def stack(sentences, langauge_id, language):\n",
    "    length = len(sentences)\n",
    "    \n",
    "    target = [langauge_id] * length\n",
    "    lang = [language] * length\n",
    "    \n",
    "    df = pd.DataFrame(np.c_[sentences, target, lang], columns=['Sentences','Target', 'Language'])\n",
    "    return df\n",
    "\n",
    "def shuffle(dataframe):\n",
    "    return dataframe.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "def preprocess():\n",
    "    data = pd.DataFrame([])\n",
    "    for code,language in languages.items():\n",
    "        extracted = extract_language(language.lower())\n",
    "        cleaned = clean(extracted)\n",
    "        dataframe = stack(cleaned, code, language)\n",
    "        \n",
    "        data = data.append(dataframe, ignore_index=True)\n",
    "    data = shuffle(data)\n",
    "    data['Target'] = data['Target'].astype(int)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_lines():\n",
    "    sum = 0\n",
    "    for code, lang in languages.items():\n",
    "        extracted = extract_language(lang.lower())\n",
    "        cleaned = clean(extracted)\n",
    "        sum += len(cleaned)\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "992612"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_lines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Target</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enako velja tudi za mala in srednje velika pod...</td>\n",
       "      <td>20</td>\n",
       "      <td>Slovenian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>az egyes árutételekhez tartozó élelmiszereket ...</td>\n",
       "      <td>14</td>\n",
       "      <td>Hungarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>det är en bra idé att utarbeta en indikator fö...</td>\n",
       "      <td>10</td>\n",
       "      <td>Swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tie būs ļoti nozīmīgi šim ziņojumam.</td>\n",
       "      <td>16</td>\n",
       "      <td>Latvian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nogmaals het moet opgehelderd worden en ik ben...</td>\n",
       "      <td>8</td>\n",
       "      <td>Dutch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992607</th>\n",
       "      <td>šiame pranešime taip pat pabrėžiamas poreikis ...</td>\n",
       "      <td>15</td>\n",
       "      <td>Lithuanian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992608</th>\n",
       "      <td>les rapports à venir nous informeront sur vos ...</td>\n",
       "      <td>6</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992609</th>\n",
       "      <td>ωστόσο είναι ικανοποιητικός ο συμβιβασμός που ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Greek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992610</th>\n",
       "      <td>czy taki produkt wzbudziłby państwa zaufanie?</td>\n",
       "      <td>17</td>\n",
       "      <td>Polish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992611</th>\n",
       "      <td>a zöldek/az európai szabad szövetség képviselő...</td>\n",
       "      <td>14</td>\n",
       "      <td>Hungarian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>992612 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Sentences  Target    Language\n",
       "0       enako velja tudi za mala in srednje velika pod...      20   Slovenian\n",
       "1       az egyes árutételekhez tartozó élelmiszereket ...      14   Hungarian\n",
       "2       det är en bra idé att utarbeta en indikator fö...      10     Swedish\n",
       "3                    tie būs ļoti nozīmīgi šim ziņojumam.      16     Latvian\n",
       "4       nogmaals het moet opgehelderd worden en ik ben...       8       Dutch\n",
       "...                                                   ...     ...         ...\n",
       "992607  šiame pranešime taip pat pabrėžiamas poreikis ...      15  Lithuanian\n",
       "992608  les rapports à venir nous informeront sur vos ...       6      French\n",
       "992609  ωστόσο είναι ικανοποιητικός ο συμβιβασμός που ...       2       Greek\n",
       "992610      czy taki produkt wzbudziłby państwa zaufanie?      17      Polish\n",
       "992611  a zöldek/az európai szabad szövetség képviselő...      14   Hungarian\n",
       "\n",
       "[992612 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Target'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         20\n",
       "1         14\n",
       "2         10\n",
       "3         16\n",
       "4          8\n",
       "          ..\n",
       "992607    15\n",
       "992608     6\n",
       "992609     2\n",
       "992610    17\n",
       "992611    14\n",
       "Name: Target, Length: 992612, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y = tf.keras.utils.to_categorical(data['Target'], num_classes=21)\n",
    "y = data['Target']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = tf.keras.preprocessing.text.Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok.fit_on_texts(data['Sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = tok.texts_to_sequences(data['Sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1050038"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = len(tok.word_index) + 1\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = tf.keras.preprocessing.sequence.pad_sequences(texts,maxlen=(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=vocab,\n",
    "                              output_dim=128,\n",
    "                             input_length=100),\n",
    "    #tf.keras.layers.LSTM(200),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(21, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 128)          134404864 \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 12800)             51200     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 21)                268821    \n",
      "=================================================================\n",
      "Total params: 134,724,885\n",
      "Trainable params: 134,699,285\n",
      "Non-trainable params: 25,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pad, np.array(y), test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 893350 samples, validate on 99262 samples\n",
      "Epoch 1/100\n",
      "893350/893350 [==============================] - 967s 1ms/sample - loss: 0.1106 - accuracy: 0.9770 - val_loss: 0.0480 - val_accuracy: 0.9954\n",
      "Epoch 2/100\n",
      "893350/893350 [==============================] - 957s 1ms/sample - loss: 0.0070 - accuracy: 0.9981 - val_loss: 0.0156 - val_accuracy: 0.9956\n",
      "Epoch 3/100\n",
      "893350/893350 [==============================] - 958s 1ms/sample - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0135 - val_accuracy: 0.9965\n",
      "Epoch 4/100\n",
      "893350/893350 [==============================] - 958s 1ms/sample - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0172 - val_accuracy: 0.9958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f77e6d0e9b0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=100, batch_size=2048, validation_data=(X_test, y_test),\n",
    "          callbacks=[tf.keras.callbacks.EarlyStopping(),\n",
    "                     tf.keras.callbacks.TensorBoard(log_dir='./graph', write_graph=True, write_images=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_three.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer_three.json', 'wb') as handle:\n",
    "    pickle.dump(tok, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer_three.json', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Just testing :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = ['hello world']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tf.keras.preprocessing.sequence.pad_sequences(tok.texts_to_sequences(test_text), maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages.get(model.predict_classes(text)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[515459, 2546]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(test_text), maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages.get(model.predict_classes(text)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
