model_one: Associates with tokenizer_one:
    > Dataset vocabulary = 93722
    > Input length = 120
    > Stopped during early stopping
    > Trained on 
        * epochs = 10
        * batch_size = 512
        * callbacks = Earlystopping and tensorboard(might not available now)
    > epochs history
        * epoch 1
            $ loss -> 2.9259, accuracy -> 0.1630, val_loss -> 2.7910, val_accuracy -> 0.3877
        * epoch 2
            $ loss -> 2.2906, accuracy -> 0.4819, val_loss -> 1.6749, val_accuracy -> 0.5407
        * epoch 3
            $ loss -> 1.4094, accuracy -> 0.6893, val_loss -> 1.0095, val_accuracy -> 0.8401
        * epoch 4
            $ loss -> 0.6024, accuracy -> 0.9304, val_loss -> 0.4143, val_accuracy -> 0.9488
        * epoch 5
            $ loss -> 0.2346, accuracy -> 0.9764, val_loss -> 0.2058, val_accuracy -> 0.9698
        * epoch 6
            $ loss -> 0.1238, accuracy -> 0.9861, val_loss -> 0.1581, val_accuracy -> 0.9679
        * epoch 7
            $ loss -> 0.0766, accuracy -> 0.9920, val_loss -> 0.1455, val_accuracy -> 0.9605
        * epoch 8
            $ loss -> 0.0672, accuracy -> 0.9927, val_loss -> 0.1081, val_accuracy -> 0.9821
        * epoch 9
            $ loss -> 0.0462, accuracy -> 0.9953, val_loss -> 0.1200, val_accuracy -> 0.9704

model_two: Associates with tokenizer_two:
    > Dataset vocabulary = 993071 (current Dataset)
    > Input length = 100
    > Stopped during Earlystopping
    > Trained on 
        * epochs = 100
        * batch_size = 512
        * callbacks = Earlystopping and tensorboard(might not available now)
    > epoch history
        * epoch 1
            $ loss -> 0.1291, accuracy -> 0.9786, val_loss -> 0.0158, val_accuracy -> 0.9963
        * epoch 2
            $ loss -> 0.0122, accuracy -> 0.9973, val_loss -> 0.0120, val_accuracy -> 0.9970
        * epoch 3
            $ loss -> 0.0085, accuracy -> 0.9982, val_loss -> 0.0117, val_accuracy -> 0.9969
        * epoch 4
            $ loss -> 0.0067, accuracy -> 0.9986, val_loss -> 0.0113, val_accuracy -> 0.9971
        * epoch 5
            $ loss -> 0.0055, accuracy -> 0.9988, val_loss -> 0.0115, val_accuracy -> 0.9972